name: Scrape Data, build and upload Model

on:
  push:
  workflow_dispatch:

jobs:
  build:
    runs-on: ubuntu-latest
    steps:
      - name: checkout repo content
        uses: actions/checkout@v3 # checkout the repository content to github runner

      - name: setup python
        uses: actions/setup-python@v4
        with:
          python-version: "3.12.1" # install the python version needed
          cache: "pip"

      - name: Set PYTHONPATH
        run: echo "PYTHONPATH=$GITHUB_WORKSPACE" >> $GITHUB_ENV

      - name: install python packages
        run: pip install -r requirements.txt

      - name: setup playwright
        run: playwright install

      - name: scrape
        env:
          MONGODB_URI: ${{ secrets.MONGODB_URI }}
        run: python scrape/scrape.py
        continue-on-error: true

      - name: train and optimize model
        env:
          AZURE_CONNECTION_STRING: ${{ secrets.AZURE_CONNECTION_STRING }}
          MONGODB_URI: ${{ secrets.MONGODB_URI }}
        run: python model/forest.py

      - name: upload model
        env:
          AZURE_CONNECTION_STRING: ${{ secrets.AZURE_CONNECTION_STRING }}
        run: python model/blob_accessor.py

      - name: Build Docker Image
        run: docker build -t lukasweibel99/rentestimator .

      - name: Log in to Dockerhub and push image
        env:
          DOCKER_USERNAME: ${{ secrets.DOCKER_USERNAME }}
          DOCKER_PASSWORD: ${{ secrets.DOCKER_PASSWORD }}
        run: |
          echo "${{ secrets.DOCKER_PASSWORD }}" | docker login -u "${{ secrets.DOCKER_USERNAME }}" --password-stdin
          docker push lukasweibel99/rentestimator:latest
